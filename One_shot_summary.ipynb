{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:green;'><center>Neural Network \n",
    "Assignments</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue;'>Introduction to Deep Learning Assignment questions.\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Q1. What is Deep Learning and Its Significance in Artificial Intelligence?</h3>\n",
    "Deep Learning is a subfield of machine learning that uses artificial neural networks with multiple layers (known as deep networks) to model complex patterns in data. It allows computers to learn directly from raw data, such as images, text, or sound, by discovering hierarchical representations and making data-driven decisions.\n",
    "\n",
    "Significance in AI:\n",
    "\n",
    "- Human-Level Performance: Deep learning models can achieve human-level accuracy in many tasks, including image recognition, language translation, and speech recognition.\n",
    "- End-to-End Learning: Unlike traditional AI systems, which rely on handcrafted features, deep learning enables end-to-end learning, automating the feature extraction process.\n",
    "- Handling Big Data: Deep learning algorithms can scale with vast datasets, making them ideal for applications involving large, complex data.\n",
    "\n",
    "<h3>Q2. Fundamental Components of Artificial Neural Networks</h3>\n",
    "An Artificial Neural Network (ANN) is modeled after the human brain, consisting of layers of connected nodes (neurons). The fundamental components include:\n",
    "\n",
    "- Neurons (Nodes): The basic processing units that receive inputs, apply weights and biases, pass through an activation function, and produce outputs.\n",
    "- Layers: ANN has three main types of layers:\n",
    "- Input Layer: Takes in the input data.\n",
    "- Hidden Layers: Intermediate layers where feature extraction occurs through nonlinear transformations.\n",
    "- Output Layer: Produces the final output or prediction.\n",
    "- Connections (Edges): Each neuron in a layer is typically connected to neurons in the next layer, facilitating the flow of information.\n",
    "- Weights and Biases: Weights determine the influence of each connection, while biases provide an additional adjustable parameter to modify the output.\n",
    "<h3>Q3. Roles of Neurons, Connections, Weights, and Biases.</h3>\n",
    "\n",
    "- Neurons: Act as processing units that perform simple calculations on the input data, passing the output to the next layer.\n",
    "- Connections: Paths that link neurons across layers, enabling data flow. The strength of these connections is adjusted during training.\n",
    "- Weights: Each connection has an associated weight, determining the strength of influence one neuron has on the next. Weights are adjusted through training to minimize error.\n",
    "- Biases: Bias terms shift the activation of neurons, allowing the network to learn even when all inputs are zero. Biases add flexibility and improve the model’s ability to fit complex data patterns.\n",
    "<h3>Q4. Architecture of an Artificial Neural Network and Information Flow.</h3>\n",
    "The architecture of an artificial neural network consists of stacked layers of neurons connected by weights. For example, a fully connected ANN has a sequential flow:\n",
    "\n",
    "- Input Layer: Receives raw data (e.g., an image represented as pixel values).\n",
    "- Hidden Layers: Process inputs through weights, biases, and activation functions. Each neuron computes a weighted sum of inputs, applies an activation function, and passes the result to the next layer.\n",
    "- Output Layer: Produces the final output, such as a classification label or regression value.\n",
    "<h3>Q5. Perceptron Learning Algorithm and Weight Adjustment.</h3>\n",
    "The Perceptron Learning Algorithm is a fundamental algorithm used in binary classification. It involves a single-layer neural network, known as a perceptron, that makes decisions by finding a linear decision boundary.\n",
    "\n",
    "Steps in the Perceptron Learning Algorithm:\n",
    "\n",
    "1. Initialize Weights: Start with small random weights and a bias.\n",
    "\n",
    "2. Compute Output: For each input, compute the output by summing the weighted inputs and applying an activation function (often a step function).\n",
    "\n",
    "3. Update Weights: If the prediction is incorrect, adjust the weights and bias using the rule:\n",
    "New Weight=Old Weight+Learning Rate×(Target Output−Predicted Output)×Input\n",
    "<h3>Q6. Importance of Activation Functions in Hidden Layers and Examples.</h3>\n",
    "Activation functions introduce non-linearity to a neural network, enabling it to model complex data. Without activation functions, neural networks would only be able to represent linear relationships, severely limiting their usefulness.\n",
    "\n",
    "Commonly Used Activation Functions:\n",
    "\n",
    "- Sigmoid: Maps input to a range between 0 and 1, commonly used in binary classification.\n",
    "f(x) = frac{1}{1 + e^{-x}} \n",
    "\n",
    "- ReLU (Rectified Linear Unit): Outputs zero for negative values and the input value for positive values. It reduces computational load and accelerates convergence.\n",
    "f(x) = max(0, x) \n",
    "\n",
    "- Tanh: Maps input to a range between -1 and 1, providing stronger gradients than sigmoid.\n",
    "f(x) = frac{e^x - e^{-x}}{e^x + e^{-x}} \n",
    "\n",
    "- Softmax: Typically used in the output layer for multi-class classification, converting outputs to probabilities that sum to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue;'>Various Neural Network Architect Overview Assignments</h2 >\n",
    "<h3>Q1. Basic Structure of a Feedforward Neural Network (FNN) and the Purpose of the Activation Function.</h3>\n",
    "A Feedforward Neural Network (FNN) is the simplest type of artificial neural network where connections between nodes do not form cycles. Information flows in one direction—from the input layer, through the hidden layers, to the output layer.\n",
    "\n",
    "- Structure: FNNs consist of an input layer, one or more hidden layers, and an output layer. Each layer contains a set of neurons (nodes) connected to the neurons in the following layer.\n",
    "- Activation Function: The purpose of the activation function is to introduce non-linearity into the network. This non-linearity enables the network to learn complex patterns by allowing it to approximate non-linear relationships. Without activation functions, the network would only perform linear transformations, severely limiting its ability to model real-world data.\n",
    "<h3>Q2. Role of Convolutional Layers and Pooling Layers in CNNs.</h3>\n",
    "Convolutional Layers: In a Convolutional Neural Network (CNN), convolutional layers are designed to extract features from input images by applying filters or kernels. Each filter performs a convolution operation across the image, creating feature maps that highlight specific patterns (such as edges, textures, or shapes).\n",
    "\n",
    "- Pooling Layers: Pooling layers, usually max pooling or average pooling, are used to reduce the spatial dimensions (width and height) of the feature maps. This downsampling achieves several goals:\n",
    "\n",
    "- Reduces Computational Complexity: By decreasing the number of parameters, pooling layers make the network more efficient.\n",
    "- Control Overfitting: Pooling layers generalize feature extraction, focusing on the most prominent features and making the network less sensitive to positional changes.\n",
    "Preserves Key Features: Max pooling, for instance, retains the most significant features by selecting the highest value in a region, while average pooling provides an overall representation by averaging values.\n",
    "<h3>Q3. Key Characteristics of Recurrent Neural Networks (RNNs) and Their Handling of Sequential Data.</h3>\n",
    "The key characteristic that differentiates Recurrent Neural Networks (RNNs) from other neural networks is their ability to handle sequential data through loops in the network structure.\n",
    "\n",
    "- Sequential Data Handling: RNNs have recurrent connections that allow them to retain information about previous inputs, making them well-suited for sequential data like time series, language, and audio. Each RNN cell receives input from the current data point and retains information from previous steps by feeding its hidden state back into itself.\n",
    "- Memory Mechanism: RNNs maintain a hidden state that evolves with each time step, allowing the network to learn dependencies across different time steps in the sequence. This design enables RNNs to capture temporal patterns and make predictions based on the context of previous inputs.\n",
    "<h3>Q4. Components of Long Short-Term Memory (LSTM) Networks and the Vanishing Gradient Problem.</h3>\n",
    "Long Short-Term Memory (LSTM) networks are a type of RNN specifically designed to overcome the limitations of traditional RNNs, particularly the vanishing gradient problem, which can prevent the network from learning long-term dependencies.\n",
    "\n",
    "- Components of LSTM:\n",
    "\n",
    "    - Forget Gate: Determines which information from the previous hidden state should be discarded.\n",
    "    - Input Gate: Decides which new information will be stored in the cell state.\n",
    "    - Cell State: The memory component of the LSTM, which carries relevant information across time steps.\n",
    "    - Output Gate: Determines the information from the cell state that will be output as the hidden state for the next time step.\n",
    "    \n",
    "Addressing the Vanishing Gradient Problem: The cell state in an LSTM is designed to carry information over long sequences with minimal changes. The gating mechanisms control the flow of information, allowing LSTMs to maintain gradients and learn dependencies over extended time steps. This design minimizes the vanishing gradient issue and enables LSTMs to model long-term dependencies effectively.\n",
    "<h3>Q5. Roles of the Generator and Discriminator in a Generative Adversarial Network (GAN) and Their Objectives. </h3>\n",
    "In a Generative Adversarial Network (GAN), two neural networks—the generator and the discriminator—are trained in a competitive setting.\n",
    "\n",
    "- Generator: The generator network takes random noise as input and generates fake data (e.g., images) with the goal of fooling the discriminator. Its objective is to improve its ability to create realistic data samples that resemble the true data distribution.\n",
    "\n",
    "- Discriminator: The discriminator network is a classifier trained to distinguish between real data (from the training set) and fake data (generated by the generator). Its objective is to maximize its accuracy in identifying real versus fake samples.\n",
    "\n",
    "- Training Objective: The generator aims to minimize the discriminator’s ability to detect fake data, while the discriminator strives to maximize its accuracy. This adversarial process continues until the generator produces data that the discriminator cannot reliably distinguish from real data, leading to realistic generated samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue;'>Activation functions assignment questions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<h3>Q1. Explain the role of activation functions in neural networks. Compare and contrast linear and nonlinear\n",
    "activation functions. Why are nonlinear activation functions preferred in hidden layers\n",
    "</h3>\n",
    "\n",
    "<p><b>Answer: -</b></p>\n",
    "\n",
    "<em>An activation function in Deep Learning (DL) is a mathematical function applied to the output of a neuron in a neural network to introduce non-linearity. This non-linearity is crucial because it allows the neural network to learn complex patterns and relationships in data, enabling it to solve more complicated tasks like image recognition, natural language processing, and others.\n",
    "\n",
    "Activation functions determine if a neuron should be activated or not by transforming the weighted sum of inputs (linear combination) into an output that can be passed on to the next layer.</em>\n",
    "\n",
    "Importance of Activation Functions\n",
    "- Non-linearity: Activation functions allow neural networks to approximate complex, non-linear mappings between inputs and outputs.\n",
    "- Learning Capacity: Without activation functions, the network would be equivalent to a linear regression model, limiting its learning capacity.\n",
    "- Gradient Flow: They impact how gradients flow through the network during backpropagation, affecting the network’s ability to learn effectively.\n",
    "\n",
    "<h3>Comparison of Linear and Nonlinear Activation Functions</h3>\n",
    "\n",
    "<table border=\"1\" cellpadding=\"10\" cellspacing=\"0\">\n",
    "    <tr>\n",
    "        <th>Criteria</th>\n",
    "        <th>Linear Activation Function</th>\n",
    "        <th>Nonlinear Activation Function</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Definition</strong></td>\n",
    "        <td>Output is directly proportional to input, represented as ( f(x) = x ).</td>\n",
    "        <td>Applies a nonlinear transformation, allowing complex relationships to be learned.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Characteristics</strong></td>\n",
    "        <td>Output remains a simple linear function of input.</td>\n",
    "        <td>Enables the model to capture intricate features with different types of transformations.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Limitations</strong></td>\n",
    "        <td>Lacks the ability to capture complex data patterns. Multiple linear layers act as a single linear layer.</td>\n",
    "        <td>Provides flexibility for the model to approximate complex functions but may introduce vanishing gradient issues.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Use Case</strong></td>\n",
    "        <td>Commonly used in output layers for linear regression or continuous outputs.</td>\n",
    "        <td>Preferred in hidden layers to enable the network to learn non-linear patterns.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Stacking Effect</strong></td>\n",
    "        <td>Stacking multiple linear layers results in an equivalent single linear layer.</td>\n",
    "        <td>Stacking layers with nonlinear functions allows the model to build hierarchical features.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h3>Why Nonlinear Activation Functions Are Preferred in Hidden Layers</h3>\n",
    "Nonlinear functions allow hidden layers to capture complex relationships in data, enabling the network to approximate any function, not just linear mappings. Nonlinear activation functions add essential flexibility, enabling hidden layers to learn from complex data patterns.\n",
    "\n",
    "\n",
    "<h3>Q2. Describe the Sigmoid activation function. What are its characteristics, and in what type of layers is it\n",
    "commonly used? Explain the Rectified Linear Unit (ReLU) activation function. Discuss its advantages\n",
    "and potential challenges. What is the purpose of the Tanh activation function? How does it differ from\n",
    "the Sigmoid activation function\n",
    "</h3>\n",
    "\n",
    "<p><b>Answer</b></p>\n",
    "<h4 style=\"color:green;\">Sigmoid Activation Function</h4>\n",
    "The Sigmoid activation function is defined by the formula:\n",
    "\n",
    "- f(x) = 1/1+e<sup>-x</sup>\n",
    "\n",
    "It produces an S-shaped curve, which maps any real-valued number into a range between 0 and 1.\n",
    "\n",
    "- Characteristics:\n",
    "\n",
    "    - Range: 0 to 1\n",
    "    - Output Interpretation: The output can be interpreted as a probability, making it ideal for binary classification.\n",
    "    - Non-linearity: It introduces non-linearity, allowing the network to learn complex relationships.\n",
    "    - Smoothness: The function is smooth and differentiable, which makes it useful for backpropagation.\n",
    "- Common Usage:\n",
    "\n",
    "    - Sigmoid is commonly used in the output layer of binary classification models since it outputs values between 0 and 1.\n",
    "In hidden layers, Sigmoid is less commonly used due to certain limitations like the vanishing gradient problem.\n",
    "\n",
    "<h4 style=\"color:green;\">Rectified Linear Unit (ReLU) Activation Function</h4>\n",
    "The ReLU activation function is defined as:\n",
    "\n",
    "- f(x)=max(0,x)\n",
    "\n",
    "This means that it outputs zero for any negative input and outputs the input itself for any positive input.\n",
    "\n",
    "- Characteristics:\n",
    "\n",
    "    - Range: 0 to infinity for positive inputs\n",
    "    - Non-linearity: Allows the network to capture complex features in data by adding non-linearity.\n",
    "    - Sparse Activation: ReLU results in sparse activations since it outputs zero for half of the input values (negative values).\n",
    "- Advantages:\n",
    "\n",
    "    - Efficient Computation: ReLU is computationally efficient because it only involves a simple thresholding.\n",
    "    - Reduced Vanishing Gradient: Unlike Sigmoid and Tanh, ReLU helps alleviate the vanishing gradient problem, allowing gradients to propagate through deep networks more effectively.\n",
    "    - Promotes Sparse Representations: Many neurons in ReLU networks output zero, making the network computationally efficient.\n",
    "- Potential Challenges:\n",
    "\n",
    "    - Dying ReLU Problem: Neurons can \"die\" during training, especially with a high learning rate, if they consistently output zero for negative values, preventing those neurons from updating.\n",
    "    - Not Suitable for All Models: ReLU can be unstable for models with noisy data or for generative tasks where Tanh or Sigmoid may perform better.\n",
    "- Common Usage:\n",
    "\n",
    "    - ReLU is the default activation function in hidden layers for most deep learning models, especially in convolutional neural networks (CNNs) and other architectures requiring efficient computation\n",
    "\n",
    "<h4 style=\"color:green;\">Tanh Activation Function</h4>    \n",
    "The Tanh activation function, short for hyperbolic tangent, is defined as:\n",
    "\n",
    "- f(x) = e<sup>x</sup> - e<sup>-x</sup>/e<sup>x</sup> + e<sup>-x</sup>\n",
    "\n",
    "This function produces an S-shaped curve that maps input values into a range between -1 and 1.\n",
    "\n",
    "- Characteristics:\n",
    "\n",
    "    - Range: -1 to 1\n",
    "    - Output Interpretation: Centered around zero, meaning that the output can be both positive and negative, which is advantageous for certain learning tasks.\n",
    "    - Non-linearity: Like Sigmoid, Tanh is non-linear and differentiable, helping in capturing complex relationships.\n",
    "- Purpose and Advantages:\n",
    "\n",
    "    - Centered Output: The zero-centered output is beneficial for many algorithms as it enables faster convergence during training compared to Sigmoid.\n",
    "    - Strong Gradient: Tanh has a steeper gradient than Sigmoid, allowing for stronger updates, especially useful in recurrent neural networks (RNNs) where Tanh is commonly used.\n",
    "- Differences from Sigmoid:\n",
    "\n",
    "    - Range: Sigmoid outputs between 0 and 1, while Tanh outputs between -1 and 1, which helps with faster convergence.\n",
    "    - Symmetry: Tanh is symmetric around zero, making it suitable for tasks where inputs can be negative, unlike Sigmoid which may be better for probabilities or strictly positive interpretations.\n",
    "- Common Usage:\n",
    "\n",
    "    - Tanh is frequently used in hidden layers of RNNs and sometimes in other types of neural networks when zero-centered outputs are beneficial for faster training.\n",
    "<h3>Q3. Discuss the significance of activation functions in the hidden layers of a neural network.</h3>\n",
    "<p><b>Answer.</b></p>\n",
    "Activation functions in the hidden layers of a neural network are essential for enabling the network to learn complex patterns and perform well on non-linear tasks. Here’s a breakdown of their significance:\n",
    "\n",
    "- Activation functions add non-linearity to the network, allowing it to learn and model complex patterns that a simple linear function cannot.\n",
    "- Without non-linear activation functions, the entire network would act as a single linear transformation, no matter how many layers it has. This would significantly limit the network's ability to capture intricate relationships in data.\n",
    "- Activation functions influence how gradients propagate back through the network during backpropagation, which is essential for updating weights.\n",
    "- Some activation functions, like ReLU, mitigate issues like the vanishing gradient problem, allowing gradients to flow more effectively, which is crucial in training deeper networks.\n",
    "- Certain activation functions, such as ReLU, output zero for negative values, which introduces sparsity into the network. Sparsity can act as a form of regularization, reducing overfitting by making the network focus on essential features rather than every input detail.\n",
    "<h3>Q4. Explain the choice of activation functions for different types of problems (e.g., classification,\n",
    "regression) in the output layer.</h3>\n",
    "<p><b>Answer: -</b></p>\n",
    "<table border=\"1\" cellpadding=\"10\" cellspacing=\"0\">\n",
    "    <tr>\n",
    "        <th>Problem Type</th>\n",
    "        <th>Common Activation Function</th>\n",
    "        <th>Reason for Choice</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Binary Classification</strong></td>\n",
    "        <td>Sigmoid</td>\n",
    "        <td>Outputs a probability value between 0 and 1, making it ideal for binary classification tasks where we need a probability or binary output.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Multi-class Classification</strong></td>\n",
    "        <td>Softmax</td>\n",
    "        <td>Softmax provides a probability distribution across multiple classes, ensuring that the sum of probabilities for all classes is 1. It is ideal for tasks with multiple classes.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Regression (Single Output)</strong></td>\n",
    "        <td>None or Linear</td>\n",
    "        <td>No activation (or a linear function) is used for regression tasks with continuous outputs, as it allows unrestricted output values suitable for regression.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Regression (Multiple Outputs)</strong></td>\n",
    "        <td>None or Linear</td>\n",
    "        <td>Similar to single-output regression, no activation function is used to allow the network to output any real-valued numbers for each target variable.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Multi-label Classification</strong></td>\n",
    "        <td>Sigmoid (per label)</td>\n",
    "        <td>Sigmoid is applied independently to each label, outputting a probability for each. This is useful when each sample can belong to multiple labels.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Ordinal Regression</strong></td>\n",
    "        <td>Softmax (with ordered classes)</td>\n",
    "        <td>Softmax may be used to model probabilities of ordered classes, but with specific loss functions that handle order in the outputs.</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q5.  Experiment with different activation functions (e.g., ReLU, Sigmoid, Tanh) in a simple neural network\n",
    "architecture. Compare their effects on convergence and performance.</h3>\n",
    "<p><b>Answer: -</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with relu activation function...\n",
      "Relu - Training Time: 48.69s, Test Accuracy: 0.9795\n",
      "\n",
      "Training with sigmoid activation function...\n",
      "Sigmoid - Training Time: 38.24s, Test Accuracy: 0.9779\n",
      "\n",
      "Training with tanh activation function...\n",
      "Tanh - Training Time: 46.55s, Test Accuracy: 0.9788\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "\n",
      "Activation Function: Relu\n",
      "Training Time: 48.69s\n",
      "Test Accuracy: 0.9795\n",
      "\n",
      "Activation Function: Sigmoid\n",
      "Training Time: 38.24s\n",
      "Test Accuracy: 0.9779\n",
      "\n",
      "Activation Function: Tanh\n",
      "Training Time: 46.55s\n",
      "Test Accuracy: 0.9788\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "from keras.src.models import Sequential\n",
    "from keras.src.layers import Dense, Flatten\n",
    "from keras.src.datasets import mnist \n",
    "from keras.src.utils import to_categorical\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train/255.0 , x_test/255.0 # Normalize the data\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "def build_and_train_model(activation_function:str):\n",
    "    model=Sequential([\n",
    "        Flatten(input_shape=(28,28)),\n",
    "        Dense(128, activation=activation_function),\n",
    "        Dense(64, activation=activation_function),\n",
    "        Dense(10, activation='softmax')\n",
    "        # softmax is used for multi-class classification problem.\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    start_time=time.time()\n",
    "    history=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
    "    training_time = time.time()-start_time\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return training_time, test_accuracy, history\n",
    "\n",
    "\n",
    "# Experiment with ReLU, Sigmoid, and Tanh activation functions\n",
    "\n",
    "activation_functions=['relu', 'sigmoid', 'tanh']\n",
    "results={}\n",
    "\n",
    "for activation in activation_functions:\n",
    "    print(f\"Training with {activation} activation function...\")\n",
    "    training_time, test_accuracy, history = build_and_train_model(activation)\n",
    "    results[activation] = {\n",
    "        'Training Time': training_time,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'History': history.history\n",
    "    }\n",
    "    print(f\"{activation.capitalize()} - Training Time: {training_time:.2f}s, Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "print(\"\\n==============================================================================\\n\")\n",
    "# Display results summary\n",
    "for activation, metrics in results.items():\n",
    "    print(f\"Activation Function: {activation.capitalize()}\")\n",
    "    print(f\"Training Time: {metrics['Training Time']:.2f}s\")\n",
    "    print(f\"Test Accuracy: {metrics['Test Accuracy']:.4f}\\n\")\n",
    "\n",
    "# Visualize convergence over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "for activation in activation_functions:\n",
    "    plt.plot(results[activation]['History']['val_accuracy'], label=f\"{activation.capitalize()}\")\n",
    "\n",
    "plt.title(\"Validation Accuracy per Epoch for Different Activation Functions\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue;'>Loss Functions assignment questions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3>1. Explain the concept of a loss function in the context of deep learning. Why are loss functions important in training neural networks?</h3>\n",
    "    <p>\n",
    "        In deep learning, a loss function is a mathematical function that quantifies the difference between the predicted outputs of a neural network and the actual target values (ground truth). It provides a measure of how well the model's predictions align with the true values. The goal of training a neural network is to minimize the loss function, which means improving the model’s accuracy. The loss function guides the optimization process by providing feedback to the network during training, typically through gradient descent. By calculating the gradient of the loss with respect to the model’s parameters, the network adjusts its weights to reduce the loss and improve prediction performance.\n",
    "    </p>\n",
    "\n",
    "<h3>2. Compare and contrast commonly used loss functions in deep learning, such as Mean Squared Error (MSE), Binary Cross-Entropy, and Categorical Cross-Entropy. When would you choose one over the other?</h3>\n",
    "\n",
    "- <strong>Mean Squared Error (MSE)</strong>: This loss function is commonly used in regression problems. It calculates the average squared difference between the predicted values and the actual target values. MSE is sensitive to outliers, as large errors have a disproportionate impact on the loss.\n",
    "        <br> \n",
    "- <strong>Binary Cross-Entropy</strong>: Used for binary classification tasks where the target variable has two classes (e.g., 0 or 1). This loss function measures the difference between the predicted probability of the positive class and the actual binary labels (0 or 1). It's well-suited for problems like spam detection, medical diagnostics, and sentiment analysis.\n",
    "        <br>\n",
    "- <strong>Categorical Cross-Entropy</strong>: Used for multi-class classification tasks, where the target variable has more than two classes. It calculates the difference between the predicted class probabilities and the actual one-hot encoded labels. It is ideal for tasks like image classification (e.g., classifying images into different categories).\n",
    "        \n",
    "You would choose MSE for regression tasks, Binary Cross-Entropy for binary classification tasks, and Categorical Cross-Entropy for multi-class classification problems.\n",
    "\n",
    " <h3>3. Discuss the challenges associated with selecting an appropriate loss function for a given deep learning task. How might the choice of loss function affect the training process and model performance?</h3>\n",
    "    <p>\n",
    "        Selecting an appropriate loss function can be challenging because it directly affects the optimization process and how the model learns. The wrong loss function can result in poor model performance, slow convergence, or even failure to learn the right patterns. For example, MSE is sensitive to outliers in regression tasks, while Binary Cross-Entropy may not work well for multi-class classification. A mismatch between the task and the loss function could lead to ineffective training, gradient issues (e.g., vanishing or exploding gradients), or failure to generalize well to unseen data. The choice of loss function must align with the specific goals of the model and the type of data being processed.\n",
    "    </p>\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>4. Implement a neural network for binary classification using TensorFlow or PyTorch. Choose an appropriate loss function for this task and explain your reasoning. Evaluate the performance of your model on a test dataset.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "        # Generate a toy binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Convert to torch tensors\n",
    "X_train, X_test = torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train, y_test = torch.tensor(y_train, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        # Define a simple feedforward neural network\n",
    "class SimpleNN(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(SimpleNN, self).__init__()\n",
    "                self.fc1 = nn.Linear(20, 64)\n",
    "                self.fc2 = nn.Linear(64, 1)\n",
    "                self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = torch.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return self.sigmoid(x)\n",
    "\n",
    "        # Initialize model, loss function, and optimizer\n",
    "        # \n",
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Training loop\n",
    "for epoch in range(100):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_train).squeeze()  # Remove extra dimension for binary classification\n",
    "            loss = criterion(output, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "        # Evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "            output = model(X_test).squeeze()\n",
    "            predictions = (output > 0.5).float()\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Consider a regression problem where the target variable has outliers. How might the choice of loss function impact the model's ability to handle outliers? Propose a strategy for dealing with outliers in the context of deep learning.</h3>\n",
    "    \n",
    "- In regression tasks, loss functions like Mean Squared Error (MSE) are highly sensitive to outliers, as the error for an outlier is squared, leading to a disproportionately large contribution to the overall loss. This can make the model focus too much on outliers and reduce its ability to generalize to the majority of the data.\n",
    " \n",
    "- A strategy to handle outliers is to use a loss function that is less sensitive to extreme values, such as the Mean Absolute Error (MAE), which treats all errors equally regardless of magnitude. Another approach could be using a robust loss function like Huber Loss, which combines MSE and MAE, providing a balance between being sensitive to small errors and resistant to large outliers. Additionally, identifying and removing outliers or using techniques like data normalization can help improve model performance in the presence of outliers.\n",
    "\n",
    "\n",
    " <h3>6. Explore the concept of weighted loss functions in deep learning. When and why might you use weighted loss functions? Provide examples of scenarios where weighted loss functions could be beneficial.</h3>\n",
    "\n",
    "- Weighted loss functions assign different importance to different samples in the training data. This can be useful in cases where the data is imbalanced, meaning one class or group of examples is underrepresented. In such scenarios, a model may bias its predictions toward the majority class, neglecting the minority class.\n",
    "\n",
    "- Weighted loss functions allow the model to give more emphasis to the minority class or more critical examples. For instance, in imbalanced classification problems (e.g., fraud detection, rare disease detection), a weighted loss function can be used to penalize the model more for incorrect predictions on the minority class, ensuring that the model learns to handle these cases properly.\n",
    "        \n",
    "- Another use case is in tasks where some data points are more important than others. For example, in medical diagnostics, misclassifying a positive cancer diagnosis might be more critical than misclassifying a benign case. In this case, a weighted loss function can be used to penalize the misclassification of more important samples more heavily.\n",
    " \n",
    "\n",
    " <h3>7. Investigate how the choice of activation function interacts with the choice of loss function in deep learning models. Are there any combinations of activation functions and loss functions that are particularly effective or problematic?</h3>\n",
    "\n",
    "The choice of activation function and loss function should be consistent to ensure effective training. For example:\n",
    "        \n",
    "- For binary classification, it is common to use the <strong>sigmoid activation function</strong> in the output layer, which outputs values between 0 and 1, and combine it with <strong>binary cross-entropy loss</strong>, which is designed for binary outcomes (0 or 1). This combination works well because the sigmoid output directly maps to probabilities, which is what the loss function expects.\n",
    "        \n",
    "- For multi-class classification, the <strong>softmax activation function</strong> is typically used in the output layer, which converts logits to a probability distribution across multiple classes. This works well with <strong>categorical cross-entropy loss</strong>, which compares the predicted probability distribution to the true distribution (usually represented as a one-hot vector).\n",
    "        \n",
    "- For regression problems, the <strong>linear activation function</strong> is commonly used in the output layer, as it can output a continuous range of values. This works well with <strong>Mean Squared Error (MSE)</strong> or <strong>Mean Absolute Error (MAE)</strong>, which are designed to compare continuous values.\n",
    "        \n",
    "Some problematic combinations could include:\n",
    "\n",
    "- Using a <strong>sigmoid activation function</strong> with <strong>categorical cross-entropy loss</strong> in multi-class problems, as the sigmoid produces independent probabilities for each class, while categorical cross-entropy expects a probability distribution across all classes (which is better served by softmax).\n",
    "- Using a <strong>ReLU activation function</strong> in the output layer for a regression task, combined with a loss function like MSE, could lead to problems if the predicted values are non-negative (ReLU outputs non-negative values). In some cases, this might not be ideal for tasks where the output range includes negative values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue;'>Assignment Questions on Forward and Backward Propagation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Q1. Explain the concept of forward propagation in a neural network'</h3>\n",
    "Forward propagation is the process by which input data is passed through the layers of a neural network to generate an output. In this process, the input is multiplied by weights, and biases are added as the data moves from layer to layer. An activation function is applied to introduce non-linearity, allowing the network to learn complex patterns.\n",
    "\n",
    "In forward propagation:\n",
    "\n",
    "- Input data is multiplied by weights at each neuron.\n",
    "- Biases are added to these weighted sums.\n",
    "- Activation functions are applied to determine the neuron’s output.\n",
    "- The result is passed to the next layer until reaching the output layer.\n",
    "<h3>Q2. What is the purpose of the activation function in forward propagation</h3>\n",
    "The activation function introduces non-linearity into the network, allowing it to learn complex mappings between inputs and outputs. Without activation functions, the neural network would behave like a linear regression model, regardless of its depth, since combining linear transformations without non-linearity is still a linear transformation.\n",
    "\n",
    "Common Activation Functions:\n",
    "\n",
    "- Sigmoid: Maps inputs to a range between 0 and 1, useful in binary classification.\n",
    "- ReLU (Rectified Linear Unit): Outputs zero for negative values and the input itself for positive values, commonly used due to efficient computation and improved gradient flow.\n",
    "- Tanh: Maps inputs to a range between -1 and 1, often used for models where negative values need to be expressed.\n",
    "<h3>Q3.Describe the steps involved in the backward propagation (backpropagation) algorithm.</h3>\n",
    "Backpropagation is the process by which a neural network adjusts its weights and biases based on the error (or loss) in its predictions. It minimizes the error by using the gradient descent optimization method.\n",
    "\n",
    "Steps in backpropagation:\n",
    "\n",
    "- Calculate Loss: Compute the error between predicted and actual output.\n",
    "- Compute Gradients: Using the chain rule, calculate the gradients of the loss with respect to each weight and bias.\n",
    "- Update Weights and Biases: Using these gradients, update the weights and biases to reduce the loss.\n",
    "- Repeat: Iterate over multiple epochs, repeating forward and backward propagation, until the model converges (i.e., loss becomes minimal).\n",
    "<h3>Q4.What is the purpose of the chain rule in backpropagation.</h3>\n",
    "The chain rule is very important in backpropagation as it allows for the calculation of gradients with respect to all weights and biases in the network. Since the network has multiple layers, we need to use the chain rule to compute how the final loss depends on each parameter by considering how each parameter affects the next layer in a sequence.\n",
    "\n",
    "In backpropagation:\n",
    "\n",
    "- The chain rule helps calculate the derivative of the loss function with respect to each weight and bias.\n",
    "- These derivatives (gradients) indicate how much each parameter should change to reduce the loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q5.Implement the forward propagation process for a simple neural network with one hidden layer using\n",
    "NumPy.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of forward propagation: [[1.01643798]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Implement the forward propagation process\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    val= 1/1+np.exp(-x)\n",
    "    return val\n",
    "\n",
    "# Define the forward propagation function\n",
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    # Step 1: Calculate the input to the hidden layer (Z1)\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    \n",
    "    # Step 2: Apply activation function on the hidden layer (A1)\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    # Step 3: Calculate the input to the output layer (Z2)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    \n",
    "    # Step 4: Apply activation function on the output layer (A2)\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    return A2\n",
    "\n",
    "# Example setup\n",
    "np.random.seed(0)\n",
    "X = np.array([[0.5, 0.2]])  # Example input data (1 sample, 2 features)\n",
    "W1 = np.random.randn(2, 3)  # Weights for layer 1 (2 inputs, 3 neurons)\n",
    "b1 = np.random.randn(1, 3)  # Biases for layer 1 (3 neurons)\n",
    "W2 = np.random.randn(3, 1)  # Weights for layer 2 (3 inputs from hidden layer, 1 output)\n",
    "b2 = np.random.randn(1, 1)  # Biases for layer 2 (1 output neuron)\n",
    "\n",
    "# Perform forward propagation\n",
    "output = forward_propagation(X, W1, b1, W2, b2)\n",
    "print(\"Output of forward propagation:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue;'>Assignment on weight initialization techniques </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q1.What is the vanishing gradient problem in deep neural networks? How does it affect training?</h3>\n",
    "\n",
    "The vanishing gradient problem occurs when gradients, or error signals, become extremely small during backpropagation in deep neural networks. This causes layers near the input of the network to receive little to no gradient, resulting in minimal updates to their weights. Consequently, the network struggles to learn, leading to slow convergence or stagnation in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2. Explain how Xavier initialization addresses the vanishing gradient problem?</h3>\n",
    "\n",
    "Xavier initialization (also known as Glorot initialization) helps mitigate the vanishing gradient problem by setting the initial weights such that the variance of activations is preserved as they propagate forward and backward. In Xavier initialization, weights are scaled based on the number of neurons in the layer (either the previous layer or average of previous and next layers). This scaling keeps gradients and activations within a reasonable range, preventing them from becoming too small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q3. What are some common activation functions that are prone to causing vanishing gradients?</h3>\n",
    "\n",
    "Activation functions that can lead to vanishing gradients include:\n",
    "\n",
    "- Sigmoid: Maps inputs to a range between 0 and 1, leading to very small gradients for inputs with large magnitudes (positive or negative).\n",
    "- Tanh: Maps inputs to a range between -1 and 1, which can also lead to small gradients for larger inputs.\n",
    "\n",
    "Both functions \"saturate\" for high and low input values, resulting in near-zero gradients and contributing to the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q4.Define the exploding gradient problem in deep neural networks. How does it impact training?</h3>\n",
    "\n",
    "The exploding gradient problem occurs when gradients become excessively large during backpropagation, often in very deep networks. This can lead to large updates to the weights, causing instability and divergence in the training process. It is particularly problematic for recurrent neural networks, where gradients accumulate over many timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q5.What is the role of proper weight initialization in training deep neural networks?</h3>\n",
    "\n",
    "Proper weight initialization is crucial for ensuring stable gradients and efficient learning in deep neural networks. By carefully initializing weights, we can prevent gradients from vanishing or exploding, allowing the network to learn more effectively. Good initialization strategies can help maintain the variance of activations and gradients across layers, improving convergence rates and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q6.Explain the concept of batch normalization and its impact on weight initialization techniques?</h3>\n",
    "\n",
    "Batch normalization is a technique that normalizes the inputs of each layer to have a mean of zero and variance of one within each batch. This regularization reduces internal covariate shift, stabilizes training, and reduces dependence on weight initialization. Batch normalization allows for higher learning rates and can lessen the risk of vanishing or exploding gradients by maintaining a consistent distribution of layer outputs, leading to improved convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q7.Implement He initialization in Python using TensorFlow or PyTorch.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a layer with He initialization\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "layer = tf.keras.layers.Dense(units=128, kernel_initializer=initializer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a layer with He initialization\n",
    "layer = nn.Linear(in_features=256, out_features=128)\n",
    "nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue;'>Optimizers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Define the concept of optimization in the context of training neural networks. Why are optimizers important for the training process?</h3>\n",
    "    \n",
    "- In the context of training neural networks, optimization refers to the process of adjusting the model's parameters (weights and biases) to minimize the loss function. The goal is to find the optimal set of parameters that allows the model to make accurate predictions. This is typically achieved using optimization algorithms that guide the model toward the global minimum or a local minimum of the loss function.\n",
    "        \n",
    "- Optimizers are crucial because they determine how efficiently the network converges during training. They adjust the weights in such a way that the loss function is minimized over time. Without an optimizer, the model would not learn effectively, or the training process could become slow, unstable, or stuck in a poor local minimum. Common optimizers, such as Stochastic Gradient Descent (SGD), Adam, and RMSprop, help the network learn faster and more effectively.\n",
    "    \n",
    "\n",
    "<h3>2. Compare and contrast commonly used optimizers in deep learning, such as Stochastic Gradient Descent (SGD), Adam, RMSprop, and AdaGrad. What are the key differences between these optimizers, and when might you choose one over the others?</h3>\n",
    "\n",
    " 1. Stochastic Gradient Descent (SGD)\n",
    "    - This is the simplest form of gradient descent, where the model parameters are updated after processing each individual training example. It has the advantage of being computationally efficient and often works well with large datasets. However, it can be noisy and requires careful tuning of the learning rate. It may also struggle to converge quickly in some cases.\n",
    "        \n",
    "2.  Adam\n",
    "    - The Adam optimizer combines the advantages of both AdaGrad and RMSprop. It adapts the learning rate based on estimates of first and second moments of the gradients. Adam is generally more effective in practice because it works well with sparse gradients and can handle noisy data. It is computationally efficient and often converges faster than SGD.\n",
    "        \n",
    "3. RMSprop\n",
    "    - RMSprop is an adaptive learning rate method that divides the learning rate by a moving average of the squared gradients. It is well-suited for non-stationary objectives (e.g., training on noisy data). RMSprop helps avoid issues with learning rate decay but still requires the tuning of a few hyperparameters like the learning rate and the decay factor.\n",
    "        \n",
    "4. AdaGrad\n",
    "    - AdaGrad is another adaptive learning rate optimizer that scales the learning rate for each parameter inversely proportional to the square root of the sum of all past squared gradients. It is particularly effective for problems with sparse data or when certain features dominate during training. However, AdaGrad's learning rate tends to decrease too quickly over time, which can result in slow convergence.\n",
    "        \n",
    "        \n",
    "\n",
    "<h3>3. Discuss the challenges associated with selecting an appropriate optimizer for a given deep learning task. How might the choice of optimizer affect the training dynamics and convergence of the neural network?</h3>\n",
    "    \n",
    "Selecting an appropriate optimizer can be challenging because it significantly impacts the efficiency and success of the training process. Some key challenges include:\n",
    "       \n",
    "1. Learning Rate Sensitivity:  Different optimizers may require different learning rates, and selecting an incorrect value can lead to slow convergence or oscillations in the loss.\n",
    "        \n",
    "2. Convergence Speed:Some optimizers, like SGD, can converge slowly and require careful tuning of the learning rate, whereas others like Adam converge faster, but may still struggle with certain types of loss surfaces.\n",
    "        \n",
    "3. Model Type: Complex models, such as deep neural networks with many parameters, may benefit more from adaptive optimizers like Adam, which adjust learning rates dynamically. In contrast, simpler models may work well with SGD.\n",
    "        \n",
    "4. Data Type: For sparse data (e.g., text data or some types of recommender systems), AdaGrad or RMSprop might be more effective, while more standard dense datasets may perform well with SGD or Adam.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Implement a neural network for image classification using TensorFlow or PyTorch. Experiment with different optimizers and evaluate their impact on the training process and model performance. Provide insights into the advantages and disadvantages of each optimizer.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define a simple CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "# Select optimizer (Adam, SGD, RMSprop, etc.)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Try changing optimizers here (SGD, RMSprop, etc.)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):  # Train for 10 epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Investigate the concept of learning rate scheduling and its relationship with optimizers in deep learning. How does learning rate scheduling influence the training process and model convergence? Provide examples of different learning rate scheduling techniques and their practical implications.</h3>\n",
    "    <ul>\n",
    "       <li>\n",
    "        Learning rate scheduling refers to adjusting the learning rate during training based on a predefined schedule or the training progress. Proper scheduling can lead to faster convergence, better performance, and prevent overshooting the optimal solution. The key idea is to start with a larger learning rate to make faster progress initially and then reduce it to allow for finer adjustments as the model nears convergence.\n",
    "        \n",
    "</li>\n",
    "<li>\n",
    "        Some common learning rate scheduling techniques include:<br>\n",
    "        Step Decay: The learning rate is reduced by a factor at regular intervals (e.g., after every few epochs).<br>\n",
    "        Exponential Decay: The learning rate decays exponentially over time.<br>\n",
    "        Cosine Annealing: The learning rate starts high and decreases gradually, following a cosine curve.<br>\n",
    "        Cyclic Learning Rate: The learning rate cycles between a minimum and maximum value throughout training.\n",
    "    </li>\n",
    "    <li>\n",
    "        These techniques can improve convergence by preventing the model from getting stuck in local minima and can also help in finding better solutions. The choice of scheduling technique depends on the problem and the optimizer being used.</li>\n",
    "</ul>\n",
    "\n",
    " <h3>6. Explore the role of momentum in optimization algorithms, such as SGD with momentum and Adam. How does momentum affect the optimization process, and under what circumstances might it be beneficial or detrimental?</h3>\n",
    " \n",
    "- Momentum is a technique used in optimization to accelerate convergence and improve the stability of gradient descent. It adds a fraction of the previous update to the current update, smoothing the trajectory and preventing oscillations in the parameter space.\n",
    "        \n",
    "- In algorithms like SGD with momentum, the velocity of previous updates is incorporated into the current update. This allows the optimizer to \"build momentum\" and continue in the same direction even when the gradient is small or noisy. Momentum can be beneficial when training deep networks, where it helps navigate across shallow regions of the loss landscape or escape local minima.\n",
    "        \n",
    "- In contrast, too much momentum can cause the optimizer to overshoot and miss the optimal solution, especially when the loss surface has sharp minima. In practice, momentum is often used with a decay parameter that gradually reduces its effect as training progresses.\n",
    "    \n",
    "<h3>7. Discuss the importance of hyperparameter tuning in optimizing deep learning models. How do hyperparameters, such as learning rate and momentum, interact with the choice of optimizer? Propose a systematic approach for hyperparameter tuning in the context of deep learning optimization.</h3>\n",
    "    \n",
    "Hyperparameter tuning is critical for optimizing deep learning models because the performance of a neural network can be highly sensitive to the choice of hyperparameters. These include the learning rate, batch size, number of epochs, optimizer settings, and other parameters like momentum or decay factors.\n",
    "        \n",
    "A systematic approach for hyperparameter tuning might involve:\n",
    "\n",
    "- Grid Search: Testing a predefined set of values for each hyperparameter to find the combination that works best.\n",
    "- Random Search: Randomly selecting hyperparameters from a range of values. While less exhaustive than grid search, it is computationally more efficient and often yields good results.\n",
    "- Bayesian Optimization: Using probabilistic models to explore the hyperparameter space efficiently and focus on areas likely to contain optimal configurations.\n",
    "        \n",
    "Hyperparameters like learning rate and momentum interact with the choice of optimizer. For example, Adam often requires less tuning for learning rate and momentum than SGD with momentum. Fine-tuning the learning rate is critical for both types of optimizers, but SGD with momentum is more sensitive to learning rate variations and may require more careful adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue;'>Assignment questions on Vanishing Gradient Problem:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Define the vanishing gradient problem and the exploding gradient problem in the context of training deep neural networks. What are the underlying causes of each problem?</h3>\n",
    "\n",
    "- **Vanishing Gradient Problem**: The vanishing gradient problem occurs when the gradients of the loss function become very small during backpropagation, causing the weights in the earlier layers of the neural network to update very little or not at all. This can lead to very slow or stalled learning, particularly in deep networks with many layers.\n",
    "\n",
    "    - **Cause**: This problem often arises with activation functions like the sigmoid or tanh, whose gradients can become very small for large positive or negative inputs, thereby diminishing the magnitude of the gradients as they are propagated backward through each layer.\n",
    "\n",
    "- **Exploding Gradient Problem**: The exploding gradient problem is the opposite, where the gradients become excessively large during backpropagation, causing the weights to update in a very large, unstable manner. This can lead to numerical instability and result in the model diverging instead of converging.\n",
    "\n",
    "    - **Cause**: This problem is typically caused by large weights or poorly initialized parameters that lead to large gradients, especially when combined with certain activation functions or deep architectures.\n",
    "\n",
    "\n",
    "\n",
    "<h3> 2. Discuss the implications of the vanishing gradient problem and the exploding gradient problem on the training process of deep neural networks. How do these problems affect the convergence and stability of the optimization process?</h3>\n",
    "\n",
    "- **Vanishing Gradient Problem Implications**:\n",
    "    - **Slow Convergence**: When the gradients become very small, the network struggles to learn, particularly in the early layers, leading to extremely slow convergence or the inability to train effectively.\n",
    "    - **Stagnation**: In extreme cases, the learning process may stagnate, as the updates to the weights become so small that the model's performance stops improving.\n",
    "    - **Difficulty in Training Deep Networks**: Deep neural networks are particularly affected by the vanishing gradient problem, as the gradients progressively diminish as they move backward through the layers, making it hard to train deep models effectively.\n",
    "\n",
    "- **Exploding Gradient Problem Implications**:\n",
    "    - **Instability**: Large gradients can cause the weights to update too drastically, leading to instability in the learning process.\n",
    "    - **Divergence**: The model may fail to converge and instead produce increasingly large weights that cause the model's output to explode, resulting in NaN (Not a Number) errors or numerical instability.\n",
    "    - **Unstable Training**: The learning rate can become too sensitive, and the optimization process becomes difficult to control, requiring careful tuning or constraints on weight updates.\n",
    "\n",
    "\n",
    "\n",
    "<h3>3. Explore the role of activation functions in mitigating the vanishing gradient problem and the exploding gradient problem. How do activation functions such as ReLU, sigmoid, and tanh influence gradient flow during backpropagation?</h3>\n",
    "\n",
    "- **Sigmoid and Tanh**:\n",
    "    - Both the **sigmoid** and **tanh** activation functions are prone to the vanishing gradient problem, particularly when the inputs to the functions are very large or very small. This is because the gradients of both functions tend to be very small for large input values, causing the backpropagated gradients to diminish as they propagate through the layers.\n",
    "    - **Sigmoid**: The gradient of the sigmoid function becomes extremely small for large positive or negative inputs, leading to a very small gradient during backpropagation.\n",
    "    - **Tanh**: Similarly, the tanh function saturates for very high or low values, which can cause vanishing gradients, though the saturation effect is less severe than sigmoid due to the tanh function's symmetric output.\n",
    "\n",
    "- **ReLU (Rectified Linear Unit)**:\n",
    "    - The **ReLU** activation function has become popular due to its ability to mitigate the vanishing gradient problem. ReLU outputs either 0 or the input value, depending on whether the input is negative or positive, and its gradient is 1 for positive inputs. This helps maintain strong gradients during backpropagation for positive inputs.\n",
    "    - However, ReLU is not immune to problems. When inputs are negative, ReLU outputs zero and its gradient is also zero, which can lead to \"dead neurons\" in the network (i.e., neurons that stop learning entirely). This is often referred to as the \"dying ReLU\" problem.\n",
    "    - To mitigate this, variants like **Leaky ReLU** and **Parametric ReLU** have been introduced, which allow for small gradients even when the input is negative, preventing neurons from \"dying.\"\n",
    "\n",
    "- **Conclusion**:\n",
    "    - Activation functions play a critical role in controlling the flow of gradients during backpropagation. Using functions like ReLU (and its variants) helps to mitigate the vanishing gradient problem, while careful weight initialization and techniques like batch normalization can help stabilize gradient flow and prevent the exploding gradient problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
