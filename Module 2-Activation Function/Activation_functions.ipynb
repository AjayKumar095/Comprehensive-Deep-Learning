{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Activation Function in Deep Learning</center></h1>\n",
    "<em>An activation function in Deep Learning (DL) is a mathematical function applied to the output of a neuron in a neural network to introduce non-linearity. This non-linearity is crucial because it allows the neural network to learn complex patterns and relationships in data, enabling it to solve more complicated tasks like image recognition, natural language processing, and others.\n",
    "\n",
    "Activation functions determine if a neuron should be activated or not by transforming the weighted sum of inputs (linear combination) into an output that can be passed on to the next layer.</em>\n",
    "\n",
    "Importance of Activation Functions\n",
    "- Non-linearity: Activation functions allow neural networks to approximate complex, non-linear mappings between inputs and outputs.\n",
    "- Learning Capacity: Without activation functions, the network would be equivalent to a linear regression model, limiting its learning capacity.\n",
    "- Gradient Flow: They impact how gradients flow through the network during backpropagation, affecting the networkâ€™s ability to learn effectively.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
